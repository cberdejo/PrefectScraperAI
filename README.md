# Prefect Scraper AI 

[![Python](https://img.shields.io/badge/python-3.11-blue.svg)](https://www.python.org/)
[![uv](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/uv/main/assets/badge/v0.json)](https://github.com/astral-sh/uv)
[![Ruff](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/ruff/main/assets/badge/v2.json)](https://github.com/astral-sh/ruff)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

![Apache Airflow](https://img.shields.io/badge/Apache%20Airflow-017CEE?style=for-the-badge&logo=Apache%20Airflow&logoColor=white)
![PostgreSQL](https://img.shields.io/badge/PostgreSQL-316192?style=for-the-badge&logo=postgresql&logoColor=white)
![MinIO](https://img.shields.io/badge/MinIO-FF4F00?style=for-the-badge&logo=MinIO&logoColor=white)
![Docker](https://img.shields.io/badge/Docker-2496ED?style=for-the-badge&logo=docker&logoColor=white)
![Selenium](https://img.shields.io/badge/Selenium-43B02A?style=for-the-badge&logo=selenium&logoColor=white)
![BeautifulSoup](https://img.shields.io/badge/BeautifulSoup-4B0082?style=for-the-badge)
![SentenceTransformers](https://img.shields.io/badge/SentenceTransformer-FFCC00?style=for-the-badge)




This project implements a web scraping pipeline orchestrated with **Prefect**. It scrapes real estate data using **Selenium** and **BeautifulSoup**, stores the data in **PostgreSQL**, and generates **embeddings** with **SentenceTransformer** to enable advanced similarity searches. Reports and intermediate results are saved in **MinIO**.

---

## üöÄ Main Technologies Used

- **Python 3.11**: Main programming language.
- **Apache Airflow**: Orchestrates and schedules scraping and data-processing tasks.
- **PostgreSQL**: Stores structured data and embeddings.
- **MinIO**: Object storage compatible with Amazon S3, used for storing reports.
- **Selenium**: Automates interactions with dynamic websites.
- **BeautifulSoup**: Parses and extracts data from static HTML.
- **SentenceTransformer**: Generates semantic embeddings for similarity comparison.
- **SQLAlchemy**: ORM for interacting with PostgreSQL.



## üóÇÔ∏è Project Structure
```
scraping-pipeline
‚îú‚îÄ üìÅairflow_scrap
‚îÇ  ‚îú‚îÄ üìÅsrc
‚îÇ  ‚îÇ  ‚îî‚îÄ üìÅdags
‚îÇ  ‚îÇ     ‚îú‚îÄ üìÑmain.py
‚îÇ  ‚îÇ     ‚îî‚îÄ üìÑ__init__.py
‚îÇ  ‚îú‚îÄ üìÑDockerfile
‚îÇ  ‚îú‚îÄ üìÑpyproject.toml
‚îÇ  ‚îú‚îÄ üìÑREADME.md
‚îÇ  ‚îî‚îÄ üìÑuv.lock
‚îú‚îÄ üìÅprefect_scrap
‚îÇ  ‚îú‚îÄ etc[...]
‚îÇ  ‚îú‚îÄ üìÑDockerfile
‚îÇ  ‚îú‚îÄ üìÑpyproject.toml
‚îÇ  ‚îú‚îÄ üìÑREADME.md
‚îÇ  ‚îî‚îÄ üìÑuv.lock
‚îú‚îÄ üìÅscrap_utils
‚îÇ  ‚îú‚îÄ üìÅsrc
‚îÇ  ‚îÇ  ‚îú‚îÄ üìÅconfig
‚îÇ  ‚îÇ  ‚îú‚îÄ üìÅhelpers
‚îÇ  ‚îÇ  ‚îú‚îÄ üìÅmodels
‚îÇ  ‚îÇ  ‚îî‚îÄ üìÅtasks
‚îÇ  ‚îú‚îÄ üìÑREADME.md
‚îÇ  ‚îî‚îÄ üìÑuv.lock
‚îú‚îÄ üìÑ.dockerignore
‚îú‚îÄ üìÑ.gitignore
‚îú‚îÄ üìÑ.pre-commit-config.yaml
‚îú‚îÄ üìÑdocker-compose.airflow.yml
‚îú‚îÄ üìÑdocker-compose.prefect.yml
‚îú‚îÄ üìÑLICENSE
‚îî‚îÄ üìÑREADME.md
```
```
PrefectScraperAI
‚îú‚îÄ üìÅsrc
‚îÇ  ‚îú‚îÄ üìÅconfig
‚îÇ  ‚îÇ  ‚îú‚îÄ üìÑlogger.py
‚îÇ  ‚îÇ  ‚îú‚îÄ üìÑminio.py
‚îÇ  ‚îÇ  ‚îú‚îÄ üìÑpostgres.py
‚îÇ  ‚îÇ  ‚îî‚îÄ üìÑ__init__.py
‚îÇ  ‚îú‚îÄ üìÅhelpers
‚îÇ  ‚îÇ  ‚îú‚îÄ üìÑutils.py
‚îÇ  ‚îÇ  ‚îî‚îÄ üìÑ__init__.py
‚îÇ  ‚îú‚îÄ üìÅmodels
‚îÇ  ‚îÇ  ‚îú‚îÄ üìÑpydantic_models.py
‚îÇ  ‚îÇ  ‚îú‚îÄ üìÑsqlalchemy_models.py
‚îÇ  ‚îÇ  ‚îî‚îÄ üìÑ__init__.py
‚îÇ  ‚îú‚îÄ üìÅpipeline
‚îÇ  ‚îÇ  ‚îú‚îÄ üìÑmain.py
‚îÇ  ‚îÇ  ‚îú‚îÄ üìÑprefect_pipeline.py
‚îÇ  ‚îÇ  ‚îî‚îÄ üìÑ__init__.py
‚îÇ  ‚îî‚îÄ üìÅtasks
‚îÇ     ‚îú‚îÄ üìÑgenerate_embedding.py
‚îÇ     ‚îú‚îÄ üìÑload_to_postgres.py
‚îÇ     ‚îú‚îÄ üìÑscrape_pisos.py
‚îÇ     ‚îú‚îÄ üìÑscrape_solvia.py
‚îÇ     ‚îú‚îÄ üìÑupload_report.py
‚îÇ     ‚îî‚îÄ üìÑ__init__.py
‚îú‚îÄ üìÑ.dockerignore
‚îú‚îÄ üìÑ.env-template
‚îú‚îÄ üìÑ.gitignore
‚îú‚îÄ üìÑ.python-version
‚îú‚îÄ üìÑdocker-compose.yml
‚îú‚îÄ üìÑDockerfile
‚îú‚îÄ üìÑLICENSE
‚îú‚îÄ üìÑpyproject.toml
‚îú‚îÄ üìÑREADME.md
‚îî‚îÄ üìÑuv.lock
```
## ‚öôÔ∏è How to Use

### üîÅ With Docker

Clone the repository:

```bash
git clone https://github.com/cberdejo/PrefectScraperAI.git
cd web-scraping-dag
```

Build and run services:

```bash
docker-compose up --build
```

This will start:
- **PostgreSQL** on port `5432`
- **MinIO** on port `9100` (API) and `9101` (web console)
- A container that executes the pipeline via `src/main.py`

You can customize services via `docker-compose.yml`.

---

### üíª Running Locally

Make sure Python 3.11 is installed.

#### Using [uv](https://github.com/astral-sh/uv)

```bash
uv run src/main.py
```

#### Or manually:

1. Create and activate a virtual environment:

```bash
python -m venv .venv
source .venv/bin/activate  # or .venv\Scripts\activate on Windows
```

2. Install dependencies:

```bash
pip install .
```

3. Run the main flow:

```bash
python src/main.py
```

> ‚ö†Ô∏è Ensure that PostgreSQL and MinIO are running and accessible. Configure credentials via a `.env` file.



## üì¶ Environment Variables

Create a `.env` file like the following to match Docker defaults:

```env
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_USER=postgres
POSTGRES_PASSWORD=mysecretpassword
POSTGRES_DB=postgres

MINIO_ENDPOINT=http://localhost:9100
MINIO_ACCESS_KEY=minioadmin
MINIO_SECRET_KEY=minioadmin
```



## üß™ Main Scripts Overview

- `src/main.py`: Coordinates the overall pipeline execution.
- `tasks/scrape_pisos.py`: Scrapes apartments from pisos.com using Selenium.
- `tasks/scrape_solvia.py`: Scrapes listings from solvia.com using BeautifulSoup.
- `tasks/generate_embedding.py`: Transforms text data into vector embeddings using `SentenceTransformer`.
- `tasks/load_to_postgres.py`: Upserts scraped and enriched data into PostgreSQL.
- `tasks/generate_report.py`: Creates and uploads a summary report to MinIO.


## üß† Why Use Embeddings?

Embeddings convert apartment descriptions into **numerical vectors** that capture semantic meaning. This enables **search by similarity** (e.g., "Find apartments like this one") using metrics like **cosine similarity**.

You can query similar listings directly from the database using vector extensions such as [pgvector](https://github.com/pgvector/pgvector) or [PGEmbedding](https://python.langchain.com/docs/integrations/vectorstores/pgembedding/), or export them to a vector database like Qdrant, Pinecone, or FAISS.

This transforms your scraped data into a **semantic search engine** for real estate listings.



## üìÑ License

MIT ‚Äì free to use, modify and distribute.



